{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "anwarvic.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRdm5kMEWoCk"
      },
      "source": [
        "# Mount GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE2jErT2Wr4X",
        "outputId": "9d948dbc-9379-4720-edd0-5aba3b24caaf"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/urbansound8k\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWhfADaoy63dUPNEYS4wqHb7E6UwMJWyQYYMH5TG5zy388ZtR8v-Pcg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5One6ltHTnJ"
      },
      "source": [
        "# Import Needed Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI0vn_K_IT56",
        "outputId": "590ba90f-8ff6-407f-ae2b-e19dd8f49a6d"
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |▌                               | 30 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 51 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 61 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 122 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 163 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 174 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 184 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 204 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 215 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 225 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 235 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 256 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 276 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 286 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 296 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 307 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 317 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 327 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 337 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 348 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 358 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 368 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 378 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 389 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 399 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 409 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 419 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 430 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 440 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 450 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 460 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 471 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 481 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 491 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 501 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 512 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 522 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 542 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 552 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 563 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 573 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 583 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 593 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 604 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 614 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 624 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 634 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 645 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 655 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 665 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 675 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 686 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 696 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 706 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 716 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 727 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 737 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 747 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 757 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 768 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 778 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 788 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 798 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 808 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 819 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 829 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 839 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 849 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 860 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 870 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 880 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 890 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 901 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 911 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 921 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 931 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 942 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 952 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 962 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 972 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 983 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 993 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.0 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.0 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.0 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.2 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.2 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.2 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.3 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.4 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.4 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.5 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.5 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.5 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.7 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.7 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.7 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.8 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.8 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.9 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.9 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9 MB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9 MB 11.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md-aPlXbHTnW"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebXwb_T0HTna"
      },
      "source": [
        "# Loading Audio Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuP7MQBOHTnb"
      },
      "source": [
        "data_path = \"urbansound8k/\"\n",
        "train_paths = [os.path.join(data_path, f\"fold{i}\") for i in range (1, 10)]\n",
        "test_paths = [os.path.join(data_path, \"fold10\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NefJeGH7HTnb",
        "outputId": "51bc1304-42c5-4a46-c95c-a35b9b9f4e0e"
      },
      "source": [
        "info_df = pd.read_csv(os.path.join(data_path, \"UrbanSound8K.csv\"))\n",
        "info_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>slice_file_name</th>\n      <th>fsID</th>\n      <th>start</th>\n      <th>end</th>\n      <th>salience</th>\n      <th>fold</th>\n      <th>classID</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100032-3-0-0.wav</td>\n      <td>100032</td>\n      <td>0.0</td>\n      <td>0.317551</td>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>dog_bark</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100263-2-0-117.wav</td>\n      <td>100263</td>\n      <td>58.5</td>\n      <td>62.500000</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100263-2-0-121.wav</td>\n      <td>100263</td>\n      <td>60.5</td>\n      <td>64.500000</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100263-2-0-126.wav</td>\n      <td>100263</td>\n      <td>63.0</td>\n      <td>67.000000</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100263-2-0-137.wav</td>\n      <td>100263</td>\n      <td>68.5</td>\n      <td>72.500000</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>children_playing</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n\n              class  \n0          dog_bark  \n1  children_playing  \n2  children_playing  \n3  children_playing  \n4  children_playing  "
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA3USxl0HTnd"
      },
      "source": [
        "class ToMono(torch.nn.Module):\n",
        "    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "class Normalize(torch.nn.Module):\n",
        "    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n",
        "        return (waveform-waveform.mean()) / waveform.std()\n",
        "\n",
        "class Pad(torch.nn.Module):\n",
        "    def __init__(self, value: float, size: int):\n",
        "        super(Pad, self).__init__()\n",
        "        self.value = value\n",
        "        self.size = size\n",
        "    \n",
        "    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.nn.functional.pad(waveform, (0, self.size-max(waveform.shape)), \"constant\", self.value)\n",
        "\n",
        "audio_transform = torch.nn.Sequential(*[\n",
        "    ToMono(), #converts audio channels to mono \n",
        "    torchaudio.transforms.Resample(orig_freq=441000, new_freq=8000), # downsamples audio signal to 8000 HZ\n",
        "    Normalize(), # normalize audio signal to have mean=0 & std=1\n",
        "    Pad(value=0, size=32000),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKA3Xz40HTnf"
      },
      "source": [
        "class UrbanSoundDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, paths, info_df, transform=None):\n",
        "        self.transform = transform\n",
        "        self.info_df = info_df\n",
        "        self.file_list = []\n",
        "        for path in paths:\n",
        "            self.file_list.extend(glob(os.path.join(path, \"*.wav\")))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filepath = self.file_list[idx]\n",
        "        _, filename = os.path.split(filepath)\n",
        "        label = int(self.info_df[self.info_df[\"slice_file_name\"] == filename][\"classID\"])\n",
        "        waveform, sample_rate = torchaudio.load(filepath)\n",
        "        if self.transform:\n",
        "            waveform = self.transform(waveform) \n",
        "        return waveform, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2qPhx1iHTnh"
      },
      "source": [
        "train_data = UrbanSoundDataset(train_paths, info_df, audio_transform)\n",
        "test_data = UrbanSoundDataset(test_paths, info_df, audio_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyuHrPNLHTni"
      },
      "source": [
        "# train_data[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DS7mTGDNHTnj"
      },
      "source": [
        "random_seed= 42\n",
        "shuffle_dataset = True\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "train_indices = list(range(len(train_data)))\n",
        "\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(train_indices)\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMTtIVknHTnn"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euRHspEYHTno"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMM_re3-HTnp",
        "outputId": "d4d88519-4074-40d2-e8bd-51f5ff08f859"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "device(type='cuda', index=0)"
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1KmSFXC6HTnq"
      },
      "source": [
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self, channels, conv_kernels, conv_strides, conv_padding, pool_padding, num_classes=10):\n",
        "        assert len(conv_kernels) == len(channels) == len(conv_strides) == len(conv_padding)\n",
        "        super(CNN, self).__init__()\n",
        "        # create conv blocks\n",
        "        self.conv_blocks = torch.nn.ModuleList()\n",
        "        prev_channel = 1\n",
        "        for i in range(len(channels)):\n",
        "            # add stacked conv layer\n",
        "            block = []\n",
        "            for j, conv_channel in enumerate(channels[i]):\n",
        "                block.append( torch.nn.Conv1d(in_channels = prev_channel, out_channels = conv_channel, kernel_size = conv_kernels[i], stride = conv_strides[i], padding = conv_padding[i]) )\n",
        "                prev_channel = conv_channel\n",
        "                # add batch norm layer\n",
        "                block.append( torch.nn.BatchNorm1d(prev_channel) )\n",
        "                # adding ReLU\n",
        "                block.append( torch.nn.ReLU() )\n",
        "            self.conv_blocks.append( torch.nn.Sequential(*block) )\n",
        "\n",
        "        # create pool blocks\n",
        "        self.pool_blocks = torch.nn.ModuleList()\n",
        "        for i in range(len(pool_padding)):\n",
        "            # adding Max Pool (drops dims by a factor of 4)\n",
        "            self.pool_blocks.append( torch.nn.MaxPool1d(kernel_size = 4, stride = 4, padding = pool_padding[i]) )\n",
        "\n",
        "        # global pooling\n",
        "        self.global_pool = torch.nn.AdaptiveAvgPool1d(1)\n",
        "        self.linear = torch.nn.Linear(prev_channel, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, inwav):\n",
        "        for i in range(len(self.conv_blocks)):\n",
        "            # apply conv layer\n",
        "            inwav = self.conv_blocks[i](inwav)\n",
        "            # apply max_pool\n",
        "            if i < len(self.pool_blocks): inwav = self.pool_blocks[i](inwav)\n",
        "        # apply global pooling\n",
        "        out = self.global_pool(inwav).squeeze()\n",
        "        out = self.linear(out)\n",
        "        return out.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YzbBJdTeHTns"
      },
      "source": [
        "class ResBlock(torch.nn.Module):\n",
        "    def __init__(self, prev_channel, channel, conv_kernel, conv_stride, conv_pad):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.res = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(in_channels = prev_channel, out_channels = channel, kernel_size = conv_kernel, stride = conv_stride, padding = conv_pad),\n",
        "            torch.nn.BatchNorm1d(channel),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv1d(in_channels = channel, out_channels = channel, kernel_size = conv_kernel, stride = conv_stride, padding = conv_pad),\n",
        "            torch.nn.BatchNorm1d(channel),\n",
        "        )\n",
        "        self.bn = torch.nn.BatchNorm1d(channel)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.res(x)\n",
        "        if x.shape[1] == identity.shape[1]:\n",
        "            x += identity\n",
        "        # repeat the smaller block till it reaches the size of the bigger block\n",
        "        elif x.shape[1] > identity.shape[1]:\n",
        "            if x.shape[1] % identity.shape[1] == 0:\n",
        "                x += identity.repeat(1, x.shape[1]//identity.shape[1], 1)\n",
        "            else:\n",
        "                raise RuntimeError(\"Dims in ResBlock needs to be divisible on the previous dims!!\")\n",
        "        else:\n",
        "            if identity.shape[1] % x.shape[1] == 0:\n",
        "                identity += x.repeat(1, identity.shape[1]//x.shape[1], 1)\n",
        "            else:\n",
        "                raise RuntimeError(\"Dims in ResBlock needs to be divisible on the previous dims!!\")\n",
        "            x = identity\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class CNNRes(torch.nn.Module):       \n",
        "        \n",
        "    def __init__(self, channels, conv_kernels, conv_strides, conv_padding, pool_padding, num_classes=10):\n",
        "        assert len(conv_kernels) == len(channels) == len(conv_strides) == len(conv_padding)\n",
        "        super(CNNRes, self).__init__()\n",
        "        \n",
        "        # create conv block\n",
        "        prev_channel = 1\n",
        "        self.conv_block = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(in_channels = prev_channel, out_channels = channels[0][0], kernel_size = conv_kernels[0], stride = conv_strides[0], padding = conv_padding[0]),\n",
        "            # add batch norm layer\n",
        "            torch.nn.BatchNorm1d(channels[0][0]),\n",
        "            # adding ReLU\n",
        "            torch.nn.ReLU(),\n",
        "            # adding max pool\n",
        "            torch.nn.MaxPool1d(kernel_size = 4, stride = 4, padding = pool_padding[0]),\n",
        "        )\n",
        "        \n",
        "        # create res\n",
        "        prev_channel = channels[0][0]\n",
        "        self.res_blocks = torch.nn.ModuleList()\n",
        "        for i in range(1, len(channels)):\n",
        "            # add stacked res layer\n",
        "            block = []\n",
        "            for j, conv_channel in enumerate(channels[i]):\n",
        "                block.append( ResBlock(prev_channel, conv_channel, conv_kernels[i], conv_strides[i], conv_padding[i]) )\n",
        "                prev_channel = conv_channel\n",
        "            self.res_blocks.append( torch.nn.Sequential(*block) )\n",
        "\n",
        "        # create pool blocks\n",
        "        self.pool_blocks = torch.nn.ModuleList()\n",
        "        for i in range(1, len(pool_padding)):\n",
        "            # adding Max Pool (drops dims by a factor of 4)\n",
        "            self.pool_blocks.append( torch.nn.MaxPool1d(kernel_size = 4, stride = 4, padding = pool_padding[i]) )\n",
        "\n",
        "        # global pooling\n",
        "        self.global_pool = torch.nn.AdaptiveAvgPool1d(1)\n",
        "        self.linear = torch.nn.Linear(prev_channel, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, inwav):\n",
        "        inwav = self.conv_block(inwav)\n",
        "        for i in range(len(self.res_blocks)):\n",
        "            # apply conv layer\n",
        "            inwav = self.res_blocks[i](inwav)\n",
        "            # apply max_pool\n",
        "            if i < len(self.pool_blocks): inwav = self.pool_blocks[i](inwav)\n",
        "        # apply global pooling\n",
        "        out = self.global_pool(inwav).squeeze()\n",
        "        out = self.linear(out)\n",
        "        return out.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZKCNJmUoHTny"
      },
      "source": [
        "m3 = CNN(channels = [[256], [256]],\n",
        "         conv_kernels = [80, 3],\n",
        "         conv_strides = [4, 1],\n",
        "         conv_padding = [38, 1],\n",
        "         pool_padding = [0, 0])\n",
        "\n",
        "m5 = CNN(channels = [[128], [128], [256], [512]],\n",
        "         conv_kernels = [80, 3, 3, 3],\n",
        "         conv_strides = [4, 1, 1, 1],\n",
        "         conv_padding = [38, 1, 1, 1],\n",
        "         pool_padding = [0, 0, 0, 2])\n",
        "\n",
        "m11 = CNN(channels = [[64], [64]*2, [128]*2, [256]*3, [512]*2],\n",
        "          conv_kernels = [80, 3, 3, 3, 3],\n",
        "          conv_strides = [4, 1, 1, 1, 1],\n",
        "          conv_padding = [38, 1, 1, 1, 1],\n",
        "          pool_padding = [0, 0, 0, 2])\n",
        "\n",
        "m18 = CNN(channels = [[64], [64]*4, [128]*4, [256]*4, [512]*4],\n",
        "          conv_kernels = [80, 3, 3, 3, 3],\n",
        "          conv_strides = [4, 1, 1, 1, 1],\n",
        "          conv_padding = [38, 1, 1, 1, 1],\n",
        "          pool_padding = [0, 0, 0, 2])\n",
        "\n",
        "m32 = CNNRes(channels = [[48], [48]*3, [96]*4, [192]*6, [384]*3],\n",
        "          conv_kernels = [80, 3, 3, 3, 3],\n",
        "          conv_strides = [4, 1, 1, 1, 1],\n",
        "          conv_padding = [38, 1, 1, 1, 1],\n",
        "          pool_padding = [0, 0, 0, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqguBi6THTn2"
      },
      "source": [
        "# Train & Test Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6xNXzdLQHTn3"
      },
      "source": [
        "def test(model, data_loader, verbose=False):\n",
        "    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n",
        "    # Make sure the model is in evaluation mode.\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "#     print('----- Model Evaluation -----')\n",
        "    # We do not need to maintain intermediate activations while testing.\n",
        "    with torch.no_grad():\n",
        "        # Loop over test data.\n",
        "        for features, target in tqdm(data_loader, total=len(data_loader.batch_sampler), desc=\"Testing\"):\n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "            # Get the label corresponding to the highest predicted probability.\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            # Count number of correct predictions.\n",
        "            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
        "    # Print test accuracy.\n",
        "    percent = 100. * correct / len(data_loader.sampler)\n",
        "    if verbose:\n",
        "        print(f'Test accuracy: {correct} / {len(data_loader.sampler)} ({percent:.0f}%)')\n",
        "    return percent\n",
        "\n",
        "\n",
        "def train(model, criterion, data_loader, test_loader, optimizer, num_epochs):\n",
        "    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n",
        "    \n",
        "    # Move model to the device (CPU or GPU).\n",
        "    model.to(device)\n",
        "    \n",
        "    accs = []\n",
        "    # Exponential moving average of the loss.\n",
        "    ema_loss = None\n",
        "\n",
        "#     print('----- Training Loop -----')\n",
        "    # Loop over epochs.\n",
        "    for epoch in range(num_epochs):\n",
        "        tick = time.time()\n",
        "        model.train()\n",
        "        # Loop over data.\n",
        "        for batch_idx, (features, target) in tqdm(enumerate(data_loader), total=len(data_loader.batch_sampler), desc=\"training\"):\n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "            loss = criterion(output.to(device), target.to(device))\n",
        "            # Backward pass.\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # NOTE: It is important to call .item() on the loss before summing.\n",
        "            if ema_loss is None:\n",
        "                ema_loss = loss.item()\n",
        "            else:\n",
        "                ema_loss += (loss.item() - ema_loss) * 0.01\n",
        "            tock = time.time()\n",
        "        acc = test(model, test_loader, verbose=True)\n",
        "        accs.append(acc)\n",
        "        # Print out progress the end of epoch.\n",
        "        print('Epoch: {} \\tLoss: {:.6f} \\t Time taken: {:.6f} seconds'.format(epoch+1, ema_loss, tock-tick),)\n",
        "        torch.save(model.state_dict(), f'model_{epoch}.ckpt')\n",
        "        print(\"Model Saved!\")\n",
        "        if os.path.isfile(f'model_{epoch-1}.ckpt'):\n",
        "            os.remove(f'model_{epoch-1}.ckpt')\n",
        "    return accs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-88lwNdkHTn4"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LbWJYMRRHTn5"
      },
      "source": [
        "# using glorot initialization\n",
        "def init_weights(m):\n",
        "    if isinstance(m, torch.nn.Conv1d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sALA2ejTHTn6",
        "outputId": "22930d79-f567-4dbc-f269-2f4793a2d13b"
      },
      "source": [
        "model = m3\n",
        "print(\"Num Parameters:\", sum([p.numel() for p in model.parameters()]))\n",
        "model.apply(init_weights) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num Parameters: 559114\n"
          ]
        },
        {
          "data": {
            "text/plain": "CNN(\n  (conv_blocks): ModuleList(\n    (0): Sequential(\n      (0): Conv1d(1, 128, kernel_size=(80,), stride=(4,), padding=(38,))\n      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n    )\n    (1): Sequential(\n      (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n    )\n    (2): Sequential(\n      (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n    )\n    (3): Sequential(\n      (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n    )\n  )\n  (pool_blocks): ModuleList(\n    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n    (1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n    (3): MaxPool1d(kernel_size=4, stride=4, padding=2, dilation=1, ceil_mode=False)\n  )\n  (global_pool): AdaptiveAvgPool1d(output_size=1)\n  (linear): Linear(in_features=512, out_features=10, bias=True)\n)"
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrQ8l_EuHTn7"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4) #L2 regularization is added"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peV4WOJbHTn8",
        "outputId": "7807c4a5-80ed-4bcd-ca4c-c06ac1d797a0"
      },
      "source": [
        "num_epochs = 100\n",
        "accs = train(model, criterion, train_loader, test_loader, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 62/62 [04:13<00:00,  4.08s/it]\n",
            "Testing: 100%|██████████| 7/7 [00:25<00:00,  3.71s/it]\n",
            "training:   0%|          | 0/62 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 265 / 837 (32%)\n",
            "Epoch: 1 \tLoss: 2.078481 \t Time taken: 253.271105 seconds\n",
            "Model Saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training:  60%|█████▉    | 37/62 [01:01<00:39,  1.59s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so4-d4fcHTn9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(accs)\n",
        "plt.title(\"Test Accuracy\")\n",
        "plt.xlabel(\"# Epochs\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQNf00K7HTn-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHSMvhxGHTn-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69B1n6LPHTn_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}